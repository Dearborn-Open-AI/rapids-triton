W1118 16:42:09.768091 60 metrics.cc:282] Cannot get CUDA device count, GPU metrics will not be available
I1118 16:42:10.014849 60 libtorch.cc:1092] TRITONBACKEND_Initialize: pytorch
I1118 16:42:10.014882 60 libtorch.cc:1102] Triton TRITONBACKEND API version: 1.6
I1118 16:42:10.014889 60 libtorch.cc:1108] 'pytorch' TRITONBACKEND API version: 1.6
2021-11-18 16:42:10.291590: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
I1118 16:42:10.362424 60 tensorflow.cc:2170] TRITONBACKEND_Initialize: tensorflow
I1118 16:42:10.362466 60 tensorflow.cc:2180] Triton TRITONBACKEND API version: 1.6
I1118 16:42:10.362476 60 tensorflow.cc:2186] 'tensorflow' TRITONBACKEND API version: 1.6
I1118 16:42:10.362486 60 tensorflow.cc:2210] backend configuration:
{}
I1118 16:42:10.364743 60 onnxruntime.cc:1999] TRITONBACKEND_Initialize: onnxruntime
I1118 16:42:10.364771 60 onnxruntime.cc:2009] Triton TRITONBACKEND API version: 1.6
I1118 16:42:10.364781 60 onnxruntime.cc:2015] 'onnxruntime' TRITONBACKEND API version: 1.6
I1118 16:42:10.396832 60 openvino.cc:1193] TRITONBACKEND_Initialize: openvino
I1118 16:42:10.396850 60 openvino.cc:1203] Triton TRITONBACKEND API version: 1.6
I1118 16:42:10.396856 60 openvino.cc:1209] 'openvino' TRITONBACKEND API version: 1.6
W1118 16:42:10.396872 60 pinned_memory_manager.cc:236] Unable to allocate pinned system memory, pinned memory pool will not be available: no CUDA-capable device is detected
I1118 16:42:10.396885 60 cuda_memory_manager.cc:115] CUDA memory pool disabled
I1118 16:42:10.397603 60 model_repository_manager.cc:1022] loading: identity:1
I1118 16:42:10.499429 60 initialize.hpp:43] TRITONBACKEND_Initialize: rapids-identity
I1118 16:42:10.499483 60 backend.hpp:47] Triton TRITONBACKEND API version: 1.6
I1118 16:42:10.499503 60 backend.hpp:52] 'rapids-identity' TRITONBACKEND API version: 1.4
I1118 16:42:10.499565 60 model_initialize.hpp:37] TRITONBACKEND_ModelInitialize: identity (version 1)
I1118 16:42:10.502831 60 instance_initialize.hpp:46] TRITONBACKEND_ModelInstanceInitialize: identity_0 (CPU device 0)
I1118 16:42:10.503271 60 model_repository_manager.cc:1183] successfully loaded 'identity' version 1
I1118 16:42:10.503404 60 server.cc:522] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I1118 16:42:10.503516 60 server.cc:549] 
+-----------------+-------------------------------------------------------------------------+--------+
| Backend         | Path                                                                    | Config |
+-----------------+-------------------------------------------------------------------------+--------+
| pytorch         | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so                 | {}     |
| tensorflow      | /opt/tritonserver/backends/tensorflow1/libtriton_tensorflow1.so         | {}     |
| onnxruntime     | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so         | {}     |
| openvino        | /opt/tritonserver/backends/openvino/libtriton_openvino.so               | {}     |
| rapids-identity | /opt/tritonserver/backends/rapids-identity/libtriton_rapids-identity.so | {}     |
+-----------------+-------------------------------------------------------------------------+--------+

I1118 16:42:10.503570 60 server.cc:592] 
+----------+---------+--------+
| Model    | Version | Status |
+----------+---------+--------+
| identity | 1       | READY  |
+----------+---------+--------+

I1118 16:42:10.503732 60 tritonserver.cc:1920] 
+----------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                  |
+----------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                 |
| server_version                   | 2.15.0                                                                                                                                                                                 |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics |
| model_repository_path[0]         | /qa/L0_e2e/cpu_model_repository                                                                                                                                                        |
| model_control_mode               | MODE_NONE                                                                                                                                                                              |
| strict_model_config              | 1                                                                                                                                                                                      |
| rate_limit                       | OFF                                                                                                                                                                                    |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                              |
| response_cache_byte_size         | 0                                                                                                                                                                                      |
| min_supported_compute_capability | 6.0                                                                                                                                                                                    |
| strict_readiness                 | 1                                                                                                                                                                                      |
| exit_timeout                     | 30                                                                                                                                                                                     |
+----------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I1118 16:42:10.505348 60 grpc_server.cc:4117] Started GRPCInferenceService at 0.0.0.0:8001
I1118 16:42:10.505873 60 http_server.cc:2815] Started HTTPService at 0.0.0.0:8000
I1118 16:42:10.548117 60 http_server.cc:167] Started Metrics Service at 0.0.0.0:8002
Signal (15) received.
I1118 16:42:11.073757 60 server.cc:252] Waiting for in-flight requests to complete.
I1118 16:42:11.073800 60 model_repository_manager.cc:1055] unloading: identity:1
I1118 16:42:11.073979 60 server.cc:267] Timeout 30: Found 1 live models and 0 in-flight non-inference requests
I1118 16:42:11.074100 60 instance_finalize.hpp:36] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I1118 16:42:11.074149 60 model_finalize.hpp:36] TRITONBACKEND_ModelFinalize: delete model state
I1118 16:42:11.074176 60 model_repository_manager.cc:1166] successfully unloaded 'identity' version 1
